algorithm:
  policy: MultiInputPolicy
  policy_kwargs:
    features_extractor_class: StateExtractor
    features_extractor_kwargs:
      net_arch:
        state:
          mlp_layer: [192]


    net_arch:
      pi: [192, 96]
      qf: [192, 96]
    activation_fn: relu
    optimizer_kwargs:
      weight_decay: 0.00001
    share_features_extractor: False
#  learning_rate: 0.001
  learning_rate:
    class: exponential
    kwargs:
      initial: 0.02
      decay: 0.02

  horizon: 96
  tau: 0.005
  gamma: 0.99
  device: cuda
  gradient_steps: 10
  train_freq: 100
  batch_size: 25600
  actor_batch_size: 100
  actor_gradient_steps: 1
  ent_coef: auto
  buffer_size: 50000
env:
  num_agent_per_scene: 100
  max_episode_steps: 512
  scene_kwargs:
    path: VisFly/datasets/spy_datasets/configs/garage_empty
  visual: False
  device: cpu

learn:
  total_timesteps: 6000000

eval_env:
  num_agent_per_scene: 4
  visual: True
  max_episode_steps: 512
  sensor_kwargs: []
  scene_kwargs:
    path: VisFly/datasets/spy_datasets/configs/garage_empty
    render_settings:
      mode: fix
      view: custom
      resolution: [1080,1920]
      position: [[7., 6.8, 5.5], [7, 4.8, 4.5]]
      trajectory: True

test:
  is_fig: True
  is_fig_save: True
  is_render: True
  is_video: True
  is_video_save: True
  render_kwargs: {}


