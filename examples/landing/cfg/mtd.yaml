algorithm:
  policy: MultiInputPolicy
  policy_kwargs:
    features_extractor_class: StateExtractor
    features_extractor_kwargs:
      net_arch:
        state:
          mlp_layer: [192, 192]

    net_arch:
      pi: [192, 96]
      qf: [192, 96]
    activation_fn: relu
    optimizer_kwargs:
      weight_decay: 0.00001
    share_features_extractor: False
  learning_rate: 0.01
  horizon: 96
  tau: 0.005
  gamma: 0.99
  device: cuda
  gradient_steps: 10
  train_freq: 100
  batch_size: 25600
  actor_batch_size: 100
  actor_gradient_steps: 1
  ent_coef: auto
env:
  num_agent_per_scene: 100
  max_episode_steps: 256
  scene_kwargs:
    path: VisFly/datasets/spy_datasets/configs/garage_empty
  visual: False
  device: cpu

learn:
  total_timesteps: 4000000

eval_env:
  num_agent_per_scene: 4
  visual: True
  sensor_kwargs: []
  scene_kwargs:
    path: VisFly/datasets/spy_datasets/configs/garage_empty
    render_settings:
      mode: fix
      view: custom
      resolution: [1080,1920]
      position: [[7., 6.8, 5.5], [7, 4.8, 4.5]]
      trajectory: True

test:
  is_fig: True
  is_fig_save: True
  is_render: True
  is_video: True
  is_video_save: True
  render_kwargs: {}


